{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1335230,"sourceType":"datasetVersion","datasetId":775382},{"sourceId":9230310,"sourceType":"datasetVersion","datasetId":5582759},{"sourceId":9286247,"sourceType":"datasetVersion","datasetId":5621285},{"sourceId":9286337,"sourceType":"datasetVersion","datasetId":5621353},{"sourceId":194758600,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport imageio\nimport cv2\nimport glob\n\n# Parameters\nheight, width, channels = 256, 256, 3\n\n# Prepare ISIC 2018 data set\nDataset_add = '/kaggle/input/isic2018-challenge-task1-data-segmentation/'\nTr_add = 'ISIC2018_Task1-2_Training_Input'\n\nTr_list = glob.glob(Dataset_add + Tr_add + '/*.jpg')\nData_train_2018 = np.zeros([len(Tr_list), height, width, channels])\nLabel_train_2018 = np.zeros([len(Tr_list), height, width])\n\nprint('Reading ISIC 2018')\nfor idx, img_path in enumerate(Tr_list):\n    print(idx + 1)\n    img = imageio.imread(img_path)\n    img = cv2.resize(img, (width, height))\n    Data_train_2018[idx] = img\n\n    # Extract corresponding mask path\n    img_name = img_path.split('/')[-1].replace('.jpg', '_segmentation.png')\n    mask_path = Dataset_add + 'ISIC2018_Task1_Training_GroundTruth/' + img_name\n    \n    img2 = imageio.imread(mask_path)\n    img2 = cv2.resize(img2, (width, height))\n    Label_train_2018[idx] = img2 \n         \nprint('Reading ISIC 2018 finished')\n\n# Split the data\nTrain_img, Validation_img, Test_img = np.split(Data_train_2018, [1815, 1815 + 259])\nTrain_mask, Validation_mask, Test_mask = np.split(Label_train_2018, [1815, 1815 + 259])\n\n# Save the data\nnp.save('data_train', Train_img)\nnp.save('data_test', Test_img)\nnp.save('data_val', Validation_img)\n\nnp.save('mask_train', Train_mask)\nnp.save('mask_test', Test_mask)\nnp.save('mask_val', Validation_mask)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T08:37:06.345215Z","iopub.execute_input":"2024-08-31T08:37:06.345593Z","iopub.status.idle":"2024-08-31T08:41:42.182592Z","shell.execute_reply.started":"2024-08-31T08:37:06.345563Z","shell.execute_reply":"2024-08-31T08:41:42.181104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\ndevice_name=tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU not found\")\nprint(\"found gpu at: {}\".format(device_name))\nprint(\"GPU\",\"available (YES!!!!)\") if tf.config.list_physical_devices(\"GPU\") else \"not available:(\"","metadata":{"execution":{"iopub.status.busy":"2024-08-31T08:49:10.050256Z","iopub.execute_input":"2024-08-31T08:49:10.051285Z","iopub.status.idle":"2024-08-31T08:49:24.780166Z","shell.execute_reply.started":"2024-08-31T08:49:10.051249Z","shell.execute_reply":"2024-08-31T08:49:24.779029Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"convert masks in to binary format save them as in a new nympy array ","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Load masks\ntrain_masks = np.load('mask_train.npy')\nval_masks = np.load('mask_val.npy')\ntest_masks = np.load('mask_test.npy')\n\n# Ensure masks are binary (thresholding)\ntrain_masks = (train_masks > 0.5).astype(np.uint8)\nval_masks = (val_masks > 0.5).astype(np.uint8)\ntest_masks = (test_masks > 0.5).astype(np.uint8)\n\n# Save the processed binary masks\nnp.save('mask_train_binary.npy', train_masks)\nnp.save('mask_val_binary.npy', val_masks)\nnp.save('mask_test_binary.npy', test_masks)\n\nprint(\"Masks have been successfully binarized and saved.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:56:18.024766Z","iopub.status.idle":"2024-08-31T07:56:18.025148Z","shell.execute_reply.started":"2024-08-31T07:56:18.024975Z","shell.execute_reply":"2024-08-31T07:56:18.024991Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"normalize images from 0-255 to 0-1 and covert float32 and save them in new numpy array(normalized)","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Load the original images and masks (in 0-255 format)\ntrain_images = np.load('data_train.npy')\nval_images = np.load('data_val.npy')\ntest_images = np.load('data_test.npy')\n\n# Normalize the images by dividing by 255 (convert to float32)\ntrain_images_normalized = train_images.astype(np.float32) / 255.0\nval_images_normalized = val_images.astype(np.float32) / 255.0\ntest_images_normalized = test_images.astype(np.float32) / 255.0\n\n# Save the normalized numpy arrays to new files\nnp.save('data_train_normalized.npy', train_images_normalized)\nnp.save('data_val_normalized.npy', val_images_normalized)\nnp.save('data_test_normalized.npy', test_images_normalized)\n\nprint(\"Normalization and saving completed.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T06:18:38.273184Z","iopub.execute_input":"2024-08-31T06:18:38.273671Z","iopub.status.idle":"2024-08-31T06:18:49.330117Z","shell.execute_reply.started":"2024-08-31T06:18:38.273635Z","shell.execute_reply":"2024-08-31T06:18:49.327216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== normalize over the dataset \ndef dataset_normalized(imgs):\n    imgs_normalized = np.empty(imgs.shape)\n    imgs_std = np.std(imgs)\n    imgs_mean = np.mean(imgs)\n    imgs_normalized = (imgs-imgs_mean)/imgs_std\n    for i in range(imgs.shape[0]):\n        imgs_normalized[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i])-np.min(imgs_normalized[i])))\n    return imgs_normalized\n       ","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:58:26.236345Z","iopub.execute_input":"2024-08-31T07:58:26.236741Z","iopub.status.idle":"2024-08-31T07:58:26.243433Z","shell.execute_reply.started":"2024-08-31T07:58:26.23671Z","shell.execute_reply":"2024-08-31T07:58:26.242333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"normalizing way two same as that of the paper","metadata":{}},{"cell_type":"code","source":"import numpy as np\n# Load the original images and masks (in 0-255 format)\ntrain_images = np.load('/kaggle/input/isic-2018-preprocessed/data_train.npy')\nval_images = np.load('/kaggle/input/isic-2018-preprocessed/data_val.npy')\ntest_images = np.load('/kaggle/input/isic-2018-preprocessed/data_test.npy')\n\n# Normalize the images by dividing by 255 (convert to float32)\ntrain_images_normalized1 = dataset_normalized(train_images.astype(np.float32)) \nval_images_normalized1 = dataset_normalized(val_images.astype(np.float32)) \ntest_images_normalized1 = dataset_normalized(test_images.astype(np.float32))\n\n# Save the normalized numpy arrays to new files\nnp.save('data_train_normalized1.npy', train_images_normalized1)\nnp.save('data_val_normalized1.npy', val_images_normalized1)\nnp.save('data_test_normalized1.npy', test_images_normalized1)\n\nprint(\"Normalization and saving completed.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T07:58:32.942172Z","iopub.execute_input":"2024-08-31T07:58:32.942542Z","iopub.status.idle":"2024-08-31T07:58:41.071063Z","shell.execute_reply.started":"2024-08-31T07:58:32.94251Z","shell.execute_reply":"2024-08-31T07:58:41.069952Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"veryfing masks are binary and printing sample data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the binary masks\ntrain_images = np.load('data_train_normalized1.npy')\ntrain_masks = np.load('/kaggle/input/isic2018-preprocessed/mask_train_binary.npy')\nval_images = np.load('data_val_normalized1.npy')\nval_masks = np.load('/kaggle/input/isic2018-preprocessed/mask_val_binary.npy')\ntest_images = np.load('data_test_normalized1.npy')\ntest_masks = np.load('/kaggle/input/isic2018-preprocessed/mask_test_binary.npy')\n\n# Check shapes\nprint(\"Train Images Shape: \", train_images.shape)\nprint(\"Train Masks Shape: \", train_masks.shape)\nprint(\"Validation Images Shape: \", val_images.shape)\nprint(\"Validation Masks Shape: \", val_masks.shape)\nprint(\"Test Images Shape: \", test_images.shape)\nprint(\"Test Masks Shape: \", test_masks.shape)\n\n# Visualize a few samples to check if the images and masks are correct\ndef display_sample(images, masks, index):\n    \"\"\"Displays an image and its corresponding mask.\"\"\"\n    image = images[index]\n    mask = masks[index]\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(image)\n    ax[0].set_title('Image')\n    ax[1].imshow(mask)\n    ax[1].set_title('Mask')\n    plt.show()\n\n# Display a random training sample\ndisplay_sample(train_images, train_masks, index=0)\n\n# Check that masks are binary\nassert np.array_equal(np.unique(train_masks), [0, 1]), \"Train masks are not binary!\"\nassert np.array_equal(np.unique(val_masks), [0, 1]), \"Validation masks are not binary!\"\nassert np.array_equal(np.unique(test_masks), [0, 1]), \"Test masks are not binary!\"\n\nprint(\"Dataset verification completed successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T08:25:31.886999Z","iopub.execute_input":"2024-08-31T08:25:31.888081Z","iopub.status.idle":"2024-08-31T08:25:40.794172Z","shell.execute_reply.started":"2024-08-31T08:25:31.888041Z","shell.execute_reply":"2024-08-31T08:25:40.793109Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check min and max values of the images\nprint(\"Min pixel value in training images:\", np.min(train_images))\nprint(\"Max pixel value in training images:\", np.max(train_images))\n\n# Check min and max values of a specific image\nsample_image = train_images[0]\nprint(\"Min pixel value in sample image:\", np.min(sample_image))\nprint(\"Max pixel value in sample image:\", np.max(sample_image))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T08:31:54.770939Z","iopub.execute_input":"2024-08-31T08:31:54.771365Z","iopub.status.idle":"2024-08-31T08:31:55.03793Z","shell.execute_reply.started":"2024-08-31T08:31:54.771325Z","shell.execute_reply":"2024-08-31T08:31:55.036907Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"defining model unet ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.layers import BatchNormalization\n#import os\n#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n\ndef unet(input_size=(256, 256, 3)):  # Changed to 3 channels for RGB\n    inputs = Input(input_size)\n\n    # Downsampling path\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    drop3 = Dropout(0.5)(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(drop3)\n    \n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    drop4 = Dropout(0.5)(conv4)\n\n    # Upsampling path\n    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop4))\n    merge6 = concatenate([drop3, up6], axis=3)\n    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n    conv6 = BatchNormalization()(conv6)\n\n    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n    merge7 = concatenate([conv2, up7], axis=3)\n    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n    conv7 = BatchNormalization()(conv7)\n\n    up8 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n    merge8 = concatenate([conv1, up8], axis=3)\n    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n    conv8 = BatchNormalization()(conv8)\n    \n    # Output layer for binary segmentation\n    conv9 = Conv2D(1, 1, activation='sigmoid')(conv8)\n\n    # Define the model\n    model = Model(inputs=inputs, outputs=conv9)\n    \n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T08:32:47.244677Z","iopub.execute_input":"2024-08-31T08:32:47.245088Z","iopub.status.idle":"2024-08-31T08:32:47.262066Z","shell.execute_reply.started":"2024-08-31T08:32:47.245059Z","shell.execute_reply":"2024-08-31T08:32:47.2608Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the datasets\ntrain_images = np.load('data_train_normalized.npy')\ntrain_masks = np.load('mask_train_binary.npy')\nval_images = np.load('data_val_normalized.npy')\nval_masks = np.load('mask_val_binary.npy')\ntest_images = np.load('data_test_normalized.npy')\ntest_masks = np.load('mask_test_binary.npy')\n\n# Check shapes\nprint(\"Train Images Shape: \", train_images.shape)\nprint(\"Train Masks Shape: \", train_masks.shape)\nprint(\"Validation Images Shape: \", val_images.shape)\nprint(\"Validation Masks Shape: \", val_masks.shape)\nprint(\"Test Images Shape: \", test_images.shape)\nprint(\"Test Masks Shape: \", test_masks.shape)\n\n# Ensure the image shape is (256, 256, 3) and the mask shape is (256, 256)\nassert train_images.shape[1:] == (256, 256, 3), \"Training images shape mismatch!\"\nassert train_masks.shape[1:] == (256, 256), \"Training masks shape mismatch!\"\n\n# Visualize a few samples to check if the images and masks are correct\ndef display_sample(images, masks, index):\n    \"\"\"Displays an image and its corresponding mask.\"\"\"\n    image = images[index]\n    mask = masks[index]\n\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    ax[0].imshow(image)\n    ax[0].set_title('Image')\n    ax[1].imshow(mask)\n    ax[1].set_title('Mask')\n    plt.show()\n\n# Display a random training sample\ndisplay_sample(train_images, train_masks, index=0)\n\n# Check that masks are binary\nassert np.array_equal(np.unique(train_masks), [0, 1]), \"Train masks are not binary!\"\nassert np.array_equal(np.unique(val_masks), [0, 1]), \"Validation masks are not binary!\"\nassert np.array_equal(np.unique(test_masks), [0, 1]), \"Test masks are not binary!\"\n\nprint(\"Dataset verification completed successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:11:22.369562Z","iopub.execute_input":"2024-08-22T18:11:22.369912Z","iopub.status.idle":"2024-08-22T18:11:27.102995Z","shell.execute_reply.started":"2024-08-22T18:11:22.369886Z","shell.execute_reply":"2024-08-22T18:11:27.101988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"above is all preprocessing the dataset which already loaded in the datasets(input tab)","metadata":{}},{"cell_type":"code","source":"# Ensure that masks have shape (256, 256, 1)\ntrain_masks = np.expand_dims(train_masks, axis=-1)\nval_masks = np.expand_dims(val_masks, axis=-1)\ntest_masks = np.expand_dims(test_masks, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:52:58.204273Z","iopub.execute_input":"2024-08-23T19:52:58.205268Z","iopub.status.idle":"2024-08-23T19:52:58.210443Z","shell.execute_reply.started":"2024-08-23T19:52:58.205234Z","shell.execute_reply":"2024-08-23T19:52:58.209434Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Check shapes\nprint(\"Train Images Shape: \", train_images.shape)\nprint(\"Train Masks Shape: \", train_masks.shape)\nprint(\"Validation Images Shape: \", val_images.shape)\nprint(\"Validation Masks Shape: \", val_masks.shape)\nprint(\"Test Images Shape: \", test_images.shape)\nprint(\"Test Masks Shape: \", test_masks.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:52:58.279282Z","iopub.execute_input":"2024-08-23T19:52:58.279542Z","iopub.status.idle":"2024-08-23T19:52:58.293045Z","shell.execute_reply.started":"2024-08-23T19:52:58.27952Z","shell.execute_reply":"2024-08-23T19:52:58.292099Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"train","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n# Instantiate the model\nmodel = unet(input_size=(256, 256, 3))\n\n# ModelCheckpoint to save the entire model (architecture + weights)\ncheckpoint = ModelCheckpoint('unet_model.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n\n# ReduceLROnPlateau to reduce learning rate when validation loss plateaus\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n\n# EarlyStopping to stop training if validation loss doesn't improve for 10 consecutive epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n\n# Train the model with the modified setup\nhistory = model.fit(\n    train_images, train_masks,\n    validation_data=(val_images, val_masks),\n    batch_size=16,\n    epochs=25,\n    shuffle=True,\n    callbacks=[checkpoint, reduce_lr_loss, early_stopping],\n    verbose=1\n)\n\n\n# Save the final trained model\nmodel.save('unet_final_model.keras')\n\nprint(\"Training completed successfully.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n# Instantiate the model\nmodel = unet(input_size=(256, 256, 3))\n\n# ModelCheckpoint to save the entire model (architecture + weights)\ncheckpoint = ModelCheckpoint('unet_model100ep.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n\n# ReduceLROnPlateau to reduce learning rate when validation loss plateaus\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n\n# EarlyStopping to stop training if validation loss doesn't improve for 10 consecutive epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n\n# Train the model with the modified setup\nhistory = model.fit(\n    train_images, train_masks,\n    validation_data=(val_images, val_masks),\n    batch_size=8,\n    epochs=100,\n    shuffle=True,\n    callbacks=[checkpoint, reduce_lr_loss],\n    verbose=1\n)\n\n\n# Save the final trained model\nmodel.save('unet_final_model_100ep.keras')\n\nprint(\"Training completed successfully.\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to plot training and validation metrics\ndef plot_training_history(history):\n    # Plot training & validation accuracy values\n    plt.figure(figsize=(12, 4))\n    \n    # Subplot for accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper left')\n    \n    # Subplot for loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper left')\n    \n    # Display the plots\n    plt.tight_layout()\n    plt.show()\n\n# Call the function to plot the training history\nplot_training_history(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T18:48:44.684289Z","iopub.execute_input":"2024-08-23T18:48:44.684892Z","iopub.status.idle":"2024-08-23T18:48:45.242769Z","shell.execute_reply.started":"2024-08-23T18:48:44.68486Z","shell.execute_reply":"2024-08-23T18:48:45.241811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"evaluation--matrixs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import load_model\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, confusion_matrix\n\n\n\n# Load the trained model\nmodel = load_model('unet_final_model_100ep.keras')\n\n# Make predictions on the test set\npredictions = model.predict(test_images)\n\n# Binarize predictions by applying a threshold of 0.5\npredictions = (predictions > 0.5).astype(np.uint8)\n\n# Flatten the masks and predictions for evaluation\ntest_masks_flat = test_masks.flatten()\npredictions_flat = predictions.flatten()\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(test_masks_flat, predictions_flat)\nf1 = f1_score(test_masks_flat, predictions_flat)\niou = jaccard_score(test_masks_flat, predictions_flat)\nconf_matrix = confusion_matrix(test_masks_flat, predictions_flat)\n\n# Print the results\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"Jaccard Index (IoU): {iou:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T18:51:18.598678Z","iopub.execute_input":"2024-08-23T18:51:18.599113Z","iopub.status.idle":"2024-08-23T18:53:14.776776Z","shell.execute_reply.started":"2024-08-23T18:51:18.599083Z","shell.execute_reply":"2024-08-23T18:53:14.775794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"result --generated mask,true mask,image","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to display a sample test image, predicted mask, and true mask\ndef display_test_sample(images, true_masks, predicted_masks, index):\n    \"\"\"Displays test image, true mask, and predicted mask side by side.\"\"\"\n    image = images[index]\n    true_mask = true_masks[index]\n    predicted_mask = predicted_masks[index]\n\n    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n    ax[0].imshow(image)\n    ax[0].set_title('Test Image')\n\n    ax[1].imshow(true_mask, cmap='gray')\n    ax[1].set_title('True Mask')\n\n    ax[2].imshow(predicted_mask, cmap='gray')\n    ax[2].set_title('Predicted Mask')\n\n    plt.show()\n\n# Display a few test samples along with their true and predicted masks\nfor i in range(15):  # Display the first 3 samples\n    display_test_sample(test_images, test_masks, predictions, i)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T18:54:09.12619Z","iopub.execute_input":"2024-08-23T18:54:09.126892Z","iopub.status.idle":"2024-08-23T18:54:19.38423Z","shell.execute_reply.started":"2024-08-23T18:54:09.126862Z","shell.execute_reply":"2024-08-23T18:54:19.383239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"exact copy of the implemented in paper","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:53:18.366416Z","iopub.execute_input":"2024-08-23T19:53:18.366777Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null}]}